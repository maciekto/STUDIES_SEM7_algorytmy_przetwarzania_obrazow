<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>APOZ Viewer — Repository Summary & Tutorial</title>
  <style>
    body{font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.5;color:#111;margin:0;padding:24px;background:#f7f9fc}
    .wrap{max-width:980px;margin:0 auto;background:#fff;padding:28px;border-radius:10px;box-shadow:0 6px 20px rgba(17,24,39,0.06)}
    h1{Margin-top:0;font-size:24px}
    h2{font-size:18px;margin-top:20px}
    pre{background:#0f1724;color:#e6eef8;padding:12px;border-radius:6px;overflow:auto}
    code{background:#eef2ff;padding:2px 6px;border-radius:4px}
    ul{margin:0 0 12px 20px}
    .note{background:#fffbea;border-left:4px solid #f59e0b;padding:10px;border-radius:6px;margin:10px 0}
    .grid{display:grid;grid-template-columns:1fr 1fr;gap:12px}
    a{color:#0b5fff}
  </style>
</head>
<body>
  <div class="wrap">
    <h1>APOZ Viewer — Repository Summary & Tutorial</h1>
    <p>This page explains the small PyQt + OpenCV image viewer in this repository: its structure, how the pieces work together, and how to run and extend it. No prior knowledge of the used libraries is assumed.</p>

    <h2>Quick facts</h2>
    <ul>
      <li>Language: Python 3.12 (project uses a venv)</li>
      <li>GUI Toolkit: PyQt6 (Qt bindings for Python)</li>
      <li>Image I/O / processing: OpenCV (cv2) and NumPy</li>
      <li>Small helper: Pillow is listed in requirements but not used in core code</li>
      <li>Entry point: <code>app/main.py</code></li>
    </ul>

    <h2>How to run</h2>
    <ol>
      <li>Create virtualenv (example in README):
        <pre>python3.12 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt</pre>
      </li>
      <li>Run the app:
        <pre>python -m app.main</pre>
      </li>
    </ol>

    <h2>Project layout</h2>
    <div class="grid">
      <div>
        <h3>app/ (core)</h3>
        <ul>
          <li><code>main.py</code> — starts QApplication and shows MainWindow</li>
          <li><code>io/image_io.py</code> — load/save functions using OpenCV (cv2)</li>
          <li><code>model/image_store.py</code> — simple dataclass ImageDoc (holds array + path)</li>
          <li><code>ui/</code> — widgets: <code>main_window.py</code>, <code>image_view.py</code>, <code>tabs_panel.py</code> (empty)</li>
          <li><code>utils/cv_qt_convert.py</code> — convert OpenCV images (NumPy arrays) into QPixmap for display</li>
        </ul>
      </div>
      <div>
        <h3>tests/, requirements, README</h3>
        <ul>
          <li><code>requirements.txt</code> lists numpy, opencv-python, pillow, PyQt6</li>
          <li>Minimal tests exist but are not required to run the app</li>
        </ul>
      </div>
    </div>

    <h2>Key concepts — explained</h2>
    <h3>1) Image I/O (app/io/image_io.py)</h3>
    <p>The project uses OpenCV (imported as <code>cv2</code>) to read and write images. The load() function accepts a path, validates extension against a small set, and calls <code>cv2.imread(..., cv2.IMREAD_UNCHANGED)</code> which returns a NumPy array. The array has shape:</p>
    <ul>
      <li>H x W for grayscale (ndim==2)</li>
      <li>H x W x 3 for color BGR</li>
      <li>H x W x 4 for BGRA</li>
    </ul>
    <p>On save, <code>cv2.imwrite</code> writes the NumPy array back to disk.</p>

    <h3>2) ImageDoc (app/model/image_store.py)</h3>
    <p>ImageDoc is a tiny container with two fields: <code>array</code> (the NumPy image) and <code>path</code> (a pathlib.Path or None). It exposes a convenience <code>title</code> property to get a tab label.</p>

    <h3>3) Converting OpenCV image to a Qt pixmap (app/utils/cv_qt_convert.py)</h3>
    <p>Qt displays images via QPixmap / QImage. OpenCV uses BGR(A) ordering and stores pixels in NumPy arrays. The conversion code:</p>
    <ul>
      <li>For grayscale: constructs a QImage with Format_Grayscale8.</li>
      <li>For BGRA: converts to RGBA with <code>cv2.cvtColor(..., cv2.COLOR_BGRA2RGBA)</code>.</li>
      <li>For BGR: converts to RGB with <code>cv2.cvtColor(..., cv2.COLOR_BGR2RGB)</code>.</li>
    </ul>
    <p>Then QImage is wrapped into QPixmap with <code>QPixmap.fromImage</code>.</p>

    <h3>4) MainWindow & UI (app/ui/main_window.py)</h3>
    <p>MainWindow is a QMainWindow that keeps a QTabWidget as central widget. Each tab holds a QSplitter (horizontal) — initially with one ImageView inside. Features implemented:</p>
    <ul>
      <li>Open images: shows file dialog and opens one tab per selected image.</li>
      <li>Save As: saves the active ImageView's NumPy array to disk using image_io.save()</li>
      <li>Duplicate: either create a new tab with a copy of the image, or insert a side-by-side copy into the current tab's splitter.</li>
      <li>View modes: Actual size (1:1 with zoom by mouse wheel), Fit (fit to widget keeping aspect ratio), Fill (stretch to fill ignoring aspect).</li>
      <li>Full screen toggle (F11)</li>
    </ul>

    <h3>5) ImageView (app/ui/image_view.py)</h3>
    <p>ImageView is a QLabel subclass that holds a QPixmap (the Qt image). It implements modes:</p>
    <ul>
      <li>ScaleMode.ACTUAL — draw at 1:1 scaled by a zoom factor. Mouse wheel adjusts zoom when in this mode.</li>
      <li>ScaleMode.FIT — scales pixmap to the widget rect preserving aspect ratio.</li>
      <li>ScaleMode.FILL — scales pixmap to widget rect ignoring aspect ratio.</li>
    </ul>

    <h2>Typical runtime flow</h2>
    <ol>
      <li>User runs the app and clicks Open…</li>
      <li>MainWindow calls image_io.load(path) → returns NumPy array</li>
      <li>Create ImageDoc(array, path) and ImageView(doc)</li>
      <li>Convert NumPy array to QPixmap via cv_to_qpixmap and set it on ImageView</li>
      <li>ImageView draws the QPixmap according to current ScaleMode and widget size</li>
    </ol>

    <h2>Small code pointers / snippets</h2>
    <p>Open an image (simplified):</p>
    <pre>from app.io.image_io import load
from app.utils.cv_qt_convert import cv_to_qpixmap
cv_img = load('photo.jpg')  # NumPy array (BGR)
pix = cv_to_qpixmap(cv_img)  # QPixmap ready to show in QLabel</pre>

    <p>Save current image from an ImageView <code>v</code>:</p>
    <pre>from app.io.image_io import save
save(v.doc.array, 'out.png')</pre>

    <h2>Tutorial — simple tasks</h2>
    <h3>1) Add a new supported image extension</h3>
    <p>Edit <code>app/io/image_io.py</code> and add the extension to SUPPORTED set.</p>

    <h3>2) Convert displayed image to grayscale (example change)</h3>
    <p>To add a menu action that converts the active image to grayscale (in-place), add an QAction in MainWindow._build_actions and a handler like:</p>
    <pre>v = self._active_image_view()
if not v: return
import cv2
gray = cv2.cvtColor(v.doc.array, cv2.COLOR_BGR2GRAY)
v.doc.array = gray
v.set_pixmap(cv_to_qpixmap(gray))</pre>

    <h3>3) Debugging tips</h3>
    <ul>
      <li>If images don't appear, check the QImage construction (wrong stride or format causes blank pixmap).</li>
      <li>OpenCV reads BGR; colors will look swapped if you treat data as RGB without conversion.</li>
      <li>On macOS, Qt sometimes shows empty widgets until resized — the code uses splitters to avoid that.</li>
    </ul>

    <h2>Libraries — short primer</h2>
    <h3>PyQt6</h3>
    <p>Python bindings for the Qt6 framework. You create a QApplication, build widgets (QMainWindow, QLabel etc.), connect signals to slots (e.g., QAction.triggered.connect(...)) and call app.exec() to start the GUI loop.</p>

    <h3>OpenCV (cv2)</h3>
    <p>Computer vision library. In Python it exposes functions like imread, imwrite, cvtColor, and operates on NumPy arrays. OpenCV uses BGR channel order by default.</p>

    <h3>NumPy</h3>
    <p>Used as the underlying container for pixel data. Familiarity with shapes and dtype is useful: typical dtype for images is uint8.</p>

    <h2>Where to start if you want to extend the app</h2>
    <ul>
      <li>Add image processing actions (filters) in MainWindow and operate on v.doc.array — then update the view with cv_to_qpixmap.</li>
      <li>Support other file formats by delegating to Pillow if OpenCV doesn't handle them well.</li>
      <li>Add drag & drop to MainWindow to accept files dropped from the OS.</li>
    </ul>

    <div class="note">If you'd like, I can also (choose one):
      <ul>
        <li>Generate a printable PDF tutorial from this HTML</li>
        <li>Create example modifications in the codebase (e.g., add a "Grayscale" menu action)</li>
        <li>Record step-by-step screenshots or a screencast guide</li>
      </ul>
    </div>

    <p>Generated from repository analysis. File: <code>docs/summary.html</code></p>
  </div>
</body>
</html>
